{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "import math\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_keyness(fdist1, fdist2, fthreshold=5, keyness_threshold=6.6, top=100, print_table=True):\n",
    "    '''create a keyness comparison table from two frequency lists\n",
    "    '''\n",
    "    \n",
    "    c1size = sum(fdist1.values())\n",
    "    c2size = sum(fdist2.values())\n",
    "\n",
    "    \n",
    "    kdata = []\n",
    "    \n",
    "    for item, freq in fdist1.items():\n",
    "        if freq<fthreshold:\n",
    "            continue\n",
    "            \n",
    "        ref_freq = fdist2.get(item,0)\n",
    "        \n",
    "        if ref_freq<fthreshold:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        keyness = log_likelihood(freq, c1size, ref_freq, c2size)\n",
    "        \n",
    "        row = {'item': item, 'freq': freq, 'ref_freq': ref_freq, 'keyness': keyness}\n",
    "        \n",
    "        if keyness>keyness_threshold:\n",
    "        \n",
    "            kdata.append(row)\n",
    "        \n",
    "    \n",
    "    kdf = pd.DataFrame(kdata)[['item', 'freq', 'ref_freq', 'keyness']]\n",
    "    \n",
    "    kdf=kdf.sort_values('keyness', ascending=False)\n",
    "    \n",
    "    if not print_table:\n",
    "        return kdf[:top]\n",
    "    \n",
    "    template = \"{: <25}{: <10}{: <10}{:0.3f}\"\n",
    "    \n",
    "    header = \"{: <25}{: <10}{: <10}{}\".format('WORD', 'A Freq.', 'B Freq.', 'Keyness')\n",
    "    \n",
    "    print(\"{}\\n{}\".format(header, \"=\"*len(header)))\n",
    "    \n",
    "    for item, freq, ref_freq, keyness in kdf[:top].values:\n",
    "        print(template.format(item, freq, ref_freq, keyness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(item_A_freq, corpus_A_size, item_B_freq, corpus_B_size):\n",
    "    '''calculate the log likelihood score for a comparison between the frequency of two items\n",
    "    '''\n",
    "    E1 = corpus_A_size*(item_A_freq+item_B_freq) / (corpus_A_size+corpus_B_size)\n",
    "    E2 = corpus_B_size*(item_A_freq+item_B_freq) / (corpus_A_size+corpus_B_size)\n",
    "\n",
    "    G2 = 2*((item_A_freq*math.log(item_A_freq/E1)) + (item_B_freq*math.log(item_B_freq/E2)))\n",
    "    \n",
    "    sign = 1 if (item_A_freq / corpus_A_size) >= (item_B_freq / corpus_B_size) else -1\n",
    "    \n",
    "    return sign*G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keyitems(df, num=10, c1='red', c2='blue', corpusA='corpus A', corpusB='corpus B'):\n",
    "    '''create a horizontal bar plot of top/bottom N items in a keyness table\n",
    "    \n",
    "    Args:\n",
    "        df - a data frame created by calculated_keyness with cols: item, keyness\n",
    "        num - the number of top and bottom ranked items to include\n",
    "        c1/c2 - color for the bars\n",
    "        corpusA/corpusB - labels/names of corpora\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib plot \n",
    "    '''\n",
    "    def selc_df(df, x=2):\n",
    "        return df.head(x).append(df.tail(x))\n",
    "\n",
    "    tb_df=selc_df(df,num)\n",
    "    \n",
    "    yh=int(num/10)*5\n",
    "    \n",
    "    colors = [c1]*num + [c2]*num\n",
    "    \n",
    "    ax = tb_df.set_index('item')['keyness'].plot(kind='barh', zorder=2,\n",
    "                                        figsize=(8, yh),\n",
    "                                        color=colors, alpha=0.5, width=0.75)\n",
    "    \n",
    "    # Despine\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    \n",
    "    # Draw vertical axis lines\n",
    "    vals = ax.get_xticks()\n",
    "    for tick in vals:\n",
    "        ax.axvline(x=tick, linestyle='dashed', alpha=0.4, color='#eeeeee', zorder=1)\n",
    "\n",
    "        \n",
    "    ax.set_xlabel(\"Keyness\", labelpad=20, weight='bold', size=12)\n",
    "\n",
    "    # Set y-axis label\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "    ax.annotate(f'Distinctive items\\nin {corpusB}', (10,num+num/2), color=c2)\n",
    "    ax.annotate(f'Distinctive items\\nin {corpusA}', (-10,num/2), ha='right', color=c1)\n",
    "\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, lowercase=False, strip_chars=''):\n",
    "    '''create a list of tokens from a string by splitting on whitespace and applying optional normalization \n",
    "    \n",
    "    Args:\n",
    "        text        -- a string object containing the text to be tokenized\n",
    "        lowercase   -- should text string be normalized as lowercase (default: False)\n",
    "        strip_chars -- a string indicating characters to strip out of text, e.g. punctuation (default: empty string) \n",
    "        \n",
    "    Return:\n",
    "        A list of tokens\n",
    "    '''\n",
    "    \n",
    "    # create a replacement dictionary from the\n",
    "    # string of characters in the **strip_chars**\n",
    "    rdict = str.maketrans('','',strip_chars)\n",
    "    \n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    \n",
    "    tokens = text.translate(rdict).split()\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_tokens(tokens, n=1):\n",
    "    '''create a list of n-gram tokens from a list of tokens\n",
    "    \n",
    "    Args:\n",
    "        tokens -- a list of tokens\n",
    "        n      -- the size of the window to use to build n-gram token list\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "        list of n-gram strings (whitespace separated) of length n\n",
    "    '''\n",
    "    \n",
    "    if n<2 or n>len(tokens):\n",
    "        return tokens\n",
    "    \n",
    "    new_tokens = []\n",
    "    \n",
    "    for i in range(len(tokens)-n+1):\n",
    "        new_tokens.append(\" \".join(tokens[i:i+n]))\n",
    "        \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kwic(kw, text, win=4):\n",
    "    '''A basic KWIC function for a text\n",
    "    \n",
    "    Args:\n",
    "        kw   -- string match for keyword to match for each line\n",
    "        text -- a list of tokens for the text\n",
    "        \n",
    "    Return:\n",
    "        list of lines of form [ [left context words], kw, [right context words]]\n",
    "    '''\n",
    "    \n",
    "    hits = [(w,i) for i,w in enumerate(text) if w==kw]\n",
    "    \n",
    "    lines = []\n",
    "    for hit in hits:\n",
    "        left = text[hit[1]-win:hit[1]]\n",
    "        kw = text[hit[1]]\n",
    "        right = text[hit[1]+1 : hit[1]+win+1]\n",
    "        \n",
    "        \n",
    "        left = ['']*(win-len(left)) + left if len(left)<win else left\n",
    "        right = right+['']*(win-len(right)) if len(right)<win else right\n",
    "\n",
    "        \n",
    "        lines.append([left, kw, right])\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kwic(kwic, win=None):\n",
    "    '''A basic print function for a KWIC object\n",
    "    \n",
    "    Args:\n",
    "        kwic -- a list of KWIC lines of the form [ [left words], kw, [right words]]\n",
    "        win  -- if None then use all words provided in context otherwise limit by win\n",
    "        \n",
    "    Prints KWIC lines with left context width/padding win*8 characters\n",
    "    '''\n",
    "    \n",
    "    if not kwic:\n",
    "        return\n",
    "    \n",
    "    if win is None:\n",
    "        win = len(kwic[0][0])\n",
    "    \n",
    "    for line in kwic:\n",
    "        print(\"{: >{}}  {}  {}\".format(' '.join(line[0][-win:]), \n",
    "                                      win*10, \n",
    "                                      line[1], \n",
    "                                      ' '.join(line[2][:win])\n",
    "                                     )\n",
    "             )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_kwic(kwic, order=None):\n",
    "    ''' sort a kwic list using the passed positional arguments \n",
    "    \n",
    "    Args:\n",
    "        kwic   -- a list of lists [ [left tokens], kw, [right tokens]]\n",
    "        order  -- a list of one or more positional arguments of form side-pos, e.g. L1, R3, L4 (default: None)\n",
    "    \n",
    "    Returns:\n",
    "        kwic sorted for each positional argument in reverse, i.e. ['R1','L1'] sorts first by L1 and then R1\n",
    "    '''\n",
    "    if order is None:\n",
    "        return kwic\n",
    "   \n",
    "    order = [order] if not type(order) is list else order\n",
    "    order.reverse()\n",
    "    \n",
    "    for sort_term in order:\n",
    "        if not re.match('[LR][1-4]', sort_term):\n",
    "            pass\n",
    "        \n",
    "        pos1 = 0 if sort_term[0]=='L' else 2\n",
    "        pos2 = int(sort_term[1])-1\n",
    "        pos2 = 3-pos2 if sort_term[0]=='L' else pos2\n",
    "        kwic.sort(key=lambda l : l[pos1][pos2])\n",
    "    \n",
    "    return kwic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocates(tokens, kw, win=[4,4]):\n",
    "    '''return the collocates in a window around a given keyword\n",
    "    \n",
    "    Args:\n",
    "          tokens -- a list of tokens\n",
    "          kw     -- keyword string to find and get collocates for\n",
    "          win    -- a list of number of tokens to left (index 0) and right (index 1) to use; default: [4,4]\n",
    "    \n",
    "    Returns:\n",
    "          a list of contexts (matching window specification) around each instance of keyword in tokens\n",
    "    '''\n",
    "    hits = [p for p,t in enumerate(tokens) if t==kw]\n",
    "    \n",
    "    context=[]\n",
    "    for hit in hits:\n",
    "        left = [] if win[0]<1 else tokens[hit-win[0]:hit]\n",
    "        right = [] if win[1]<1 else tokens[hit+1:hit+win[1]+1]\n",
    "        \n",
    "        context.extend(left)\n",
    "        context.extend(right)\n",
    "        \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colls(texts,kw, win=[4,4]):\n",
    "    '''create a collocate frequency list for instances of a kw in a list of texts\n",
    "    \n",
    "    Args:\n",
    "        texts  -- a list of tokenized texts\n",
    "        kw     -- keyword string to find and get collocates for\n",
    "        win    -- a list of number of tokens to left (index 0) and right (index 1) to use; default: [4,4]\n",
    "    \n",
    "    Returns:\n",
    "        a list-of-tuples where each tuple is (collocate, freq_with_kw, coll_total_freq)\n",
    "    '''\n",
    "    word_dist = Counter()\n",
    "    colls = Counter()\n",
    "    for text, tokens in texts.items():\n",
    "        word_dist.update(tokens)\n",
    "        colls.update(collocates(tokens,kw, win))\n",
    "    \n",
    "    return [(str(k),v, word_dist[k]) for k,v in colls.items()], word_dist.get(kw), sum(word_dist.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_freq(freq, size, base=10000):\n",
    "    '''normalize the frequency of an item based on the size of the text/corpus using a base, e.g. per 10,000 words\n",
    "    \n",
    "    Args:\n",
    "        freq   --  the frequency of the item\n",
    "        size   --  the size (number of tokens) in the text/corpus\n",
    "        base   --  normalization unit (DEFAULT: 10,000 tokens)\n",
    "    \n",
    "    Returns:\n",
    "        normalized frequency\n",
    "    \n",
    "    '''\n",
    "    norm_freq = freq/size * base\n",
    "    return norm_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist1_size = sum(dist1.values())\n",
    "#dist2_size = sum(dist2.values())\n",
    "#dist3_size = sum(dist3.values())\n",
    "#dist4_size = sum(dist4.values())\n",
    "#dist5_size = sum(dist5.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_items(dist1, size1, dist2, size2, dist3, size3, dist4, size4, dist5, size5, items, scaling=10000, dp=15):\n",
    "    ''' given two Counter objects with common keys compare the frequency and relative frequency of list of items\n",
    "    \n",
    "    Args:\n",
    "        dist1    -- Counter frequency list object\n",
    "        dist2    -- Counter frequency list object\n",
    "        items    -- list of string items that should be keys in dist1 and dist2\n",
    "        scaling  -- normalization factor, e.g. 10,000 words (default: 100000)\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        list of tuples of form\n",
    "            (item, item_freq_dist1, norm_item_freq_dist1, item_freq_dist2, norm_item_freq_dist2)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    item_comparison = []\n",
    "    \n",
    "    for item in items:\n",
    "        \n",
    "        d1_freq = dist1.get(item,0)\n",
    "        d2_freq = dist2.get(item,0)\n",
    "        d3_freq = dist3.get(item,0)\n",
    "        d4_freq = dist4.get(item,0)\n",
    "        d5_freq = dist5.get(item,0)\n",
    "        \n",
    "        item_comparison.append((item, \n",
    "                                d1_freq, round(d1_freq/size1*scaling, dp),\n",
    "                                d2_freq, round(d2_freq/size2*scaling, dp),\n",
    "                                d3_freq, round(d3_freq/size3*scaling, dp),\n",
    "                                d4_freq, round(d4_freq/size4*scaling, dp),\n",
    "                                d5_freq, round(d5_freq/size5*scaling, dp)))\n",
    "    \n",
    "    return item_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_item(dist1, dist2,dist3,dist4,dist5, items, scaling=10000, dp=15):\n",
    "    ''' given two Counter objects with common keys compare the frequency and relative frequency of list of items\n",
    "    \n",
    "    Args:\n",
    "        dist1    -- Counter frequency list object\n",
    "        dist2    -- Counter frequency list object\n",
    "        items    -- list of string items that should be keys in dist1 and dist2\n",
    "        scaling  -- normalization factor, e.g. 10,000 words (default: 100000)\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        list of tuples of form\n",
    "            (item, item_freq_dist1, norm_item_freq_dist1, item_freq_dist2, norm_item_freq_dist2)\n",
    "    '''\n",
    "    \n",
    "    size1 = sum(dist1.values())\n",
    "    size2 = sum(dist2.values())\n",
    "    size3 = sum(dist3.values())\n",
    "    size4 = sum(dist4.values())\n",
    "    size5 = sum(dist5.values())\n",
    "    \n",
    "    \n",
    "    item_comparison = []\n",
    "    \n",
    "    for item in items:\n",
    "        \n",
    "        d1_freq = dist1.get(item,0)\n",
    "        d2_freq = dist2.get(item,0)\n",
    "        d3_freq = dist3.get(item,0)\n",
    "        d4_freq = dist4.get(item,0)\n",
    "        d5_freq = dist5.get(item,0)\n",
    "        \n",
    "        item_comparison.append((item, \n",
    "                                round(d1_freq/size1*scaling, dp),\n",
    "                                round(d2_freq/size2*scaling, dp),\n",
    "                                round(d3_freq/size3*scaling, dp),\n",
    "                                round(d4_freq/size4*scaling, dp),\n",
    "                                round(d5_freq/size5*scaling, dp)))\n",
    "    \n",
    "    return item_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_keyitems(df, n=20, c1='red', c2='blue', corpusA='corpus A', corpusB='corpus B'):\n",
    "    '''plot  top/bottom n items from a keyness analysis table\n",
    "    \n",
    "    Args:\n",
    "        df - a data frame created by calculated_keyness with cols: item, keyness\n",
    "        num - the number of top and bottom ranked items to include\n",
    "        c1/c2 - color for the bars\n",
    "    \n",
    "    Returns:\n",
    "        HTML string containing two column table\n",
    "    '''\n",
    "   \n",
    "    template = '''\n",
    "        <div style=' float:left; width: 40%; text-align: center'>\n",
    "        <h3>{}</h3>\n",
    "        {}</div>\n",
    "       <div style='width: 40%; padding-left: 20px; float: left; '>\n",
    "       <h3 style=\"text-align: center\">{}</h3>\n",
    "        {}</div>\n",
    "    '''\n",
    "\n",
    "\n",
    "    idiv = '''\n",
    "            <div style=\"font-size: {}px; color: {}; margin-bottom: 2px; float: left; \n",
    "            margin: 10px; padding: 2px; background-color: #f7f7f7; border-radius: 6px\">\n",
    "            {}</div>\n",
    "            '''\n",
    "    \n",
    "    top = df[['item', 'keyness']].head(n).values\n",
    "    bottom = df[['item', 'keyness']].tail(n).values\n",
    "\n",
    "    top_str = '\\n'.join([idiv.format(3*math.log(kness), c1, item) for size, (item, kness) in enumerate(top,1)])\n",
    "    bottom_str = '\\n'.join([idiv.format(3*math.log(abs(kness)), c2, item) for size, (item, kness) in enumerate(bottom,1)])\n",
    "    \n",
    "    \n",
    "    display(HTML(\n",
    "        template.format(corpusA,top_str, corpusB, bottom_str)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_plot(comparison_data, label1='corpus 1', label2='corpus 2', label3='corpus 3', label4='corpus 4', label5='corpus 5'):\n",
    "    ''' create a paired barplot of relative frequencies of items in two corpora\n",
    "    \n",
    "    Args:\n",
    "        comparison_data --  list of tuples produced by the compare_items() function\n",
    "        label1          --  legend label for first corpus (default: corpus 1)\n",
    "        label2          --  legend label for second corpus (default: corpus 2)\n",
    "        \n",
    "    Produces a Seaborn barplot\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    \n",
    "    df=pd.DataFrame(comparison_data)[[0,2,4,6,8,10]] \n",
    "    df.columns = ['item', label1, label2, label3, label4, label5]\n",
    "    df2=df.melt(id_vars=['item'])\n",
    "    df2.columns=['item', 'corpus', 'frequency']\n",
    "    sn.barplot(x='item',y='frequency', hue='corpus',data=df2, palette = 'OrRd')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plot(comparison_data, label1='corpus 1', label2='corpus 2', label3='corpus 3', label4='corpus 4', label5='corpus 5'):\n",
    "    ''' create a paired barplot of relative frequencies of items in two corpora\n",
    "    \n",
    "    Args:\n",
    "        comparison_data --  list of tuples produced by the compare_items() function\n",
    "        label1          --  legend label for first corpus (default: corpus 1)\n",
    "        label2          --  legend label for second corpus (default: corpus 2)\n",
    "        \n",
    "    Produces a Seaborn barplot\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    \n",
    "    df=pd.DataFrame(comparison_data)[[0,1,2,3,4,5]] \n",
    "    df.columns = ['item', label1, label2, label3, label4, label5]\n",
    "    df2=df.melt(id_vars=['item'])\n",
    "    df2.columns=['item', 'corpus', 'frequency']\n",
    "    sn.barplot(x='item',y='frequency', hue='corpus',data=df2, palette = 'OrRd')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_collocates(kw, collocate_list, num=20, show_freq=False, title=None, threshold=1):\n",
    "    ''' Create a graph of the collocates of a keyword within a specified window and threshold\n",
    "    \n",
    "    Args:\n",
    "        kw              -- keyword to place at center of graph\n",
    "        collocate_list  -- Counter object of collocate frequencies\n",
    "        num             -- the number of collocates (in descending frequency to display) [default=20]\n",
    "        show_freq       -- whether to show frequency beside edge True/False [default=False]\n",
    "        title           -- string to use as a title for the plot [default=None]\n",
    "        threshold       -- frequency threshold for showing edges [default=1]\n",
    "        \n",
    "    '''\n",
    "    cG = graphviz.Graph(engine='neato')\n",
    "    cG.attr('graph', overlap='scalexy', size=\"6,6\")\n",
    "    if title:\n",
    "        cG.attr('graph', label=title, labelloc='t', fontsize='20')\n",
    "    for item, freq in collocate_list.most_common(num):\n",
    "        if freq >= threshold:\n",
    "            cG.edge(kw.upper(), item, penwidth=str(math.log(freq,2)), \n",
    "                    label=None if not show_freq else str(freq))\n",
    "    \n",
    "    return cG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
