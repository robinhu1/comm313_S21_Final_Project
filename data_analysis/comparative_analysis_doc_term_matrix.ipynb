{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis Document Term Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm interested in seeing differences between all five sources. I believe a doc term matrix may be helpful to visualize a cross-comparison which is the purpose of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import seaborn as sn\n",
    "from collections import Counter\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.cluster import hierarchical,KMeans, linkage_tree\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_terms_texts= open('../data/text/china_daily/cd_terms_only_texts.txt').read()\n",
    "nyt_terms_texts = open('../data/text/nyt/nyt_terms_only_texts.txt').read()\n",
    "g_terms_texts = open('../data/text/guardian/g_terms_only_texts.txt').read()\n",
    "dt_terms_texts = open('../data/text/daily_telegraph/dt_terms_only_texts.txt').read()\n",
    "ht_terms_texts = open('../data/text/hindustan_times/ht_terms_only_texts.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a slice of each text since they are ridiculously long and I just want to glean some key differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [cd_terms_texts[:100000],nyt_terms_texts[:100000],dt_terms_texts[:100000],g_terms_texts[:100000],ht_terms_texts[:100000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dist=Counter()\n",
    "rows=[]\n",
    "\n",
    "\n",
    "for text in texts:\n",
    "    tokens = text.split()\n",
    "    word_dist.update(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = word_dist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = []\n",
    "for text in texts:\n",
    "    row=[]\n",
    "    tokens = text.split()\n",
    "    for item in vocab:\n",
    "        row.append(item in tokens)\n",
    "        \n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame(rows, columns = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Text {}'.format(i) for i,_ in enumerate(texts,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated figure can be found in the final data_story. I wanted to be able to load this notebook directly so I included that plot code there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
